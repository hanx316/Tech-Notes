# 字符编码基础知识

计算机在存储信息时会将所有内容都转为二进制，即一切都是0和1

每一个二进制位作为一个比特（bit），八个二进制位作为一个字节（byte），即1byte = 8bit

1bit对应了0和1两种状态，8位二进制数即可以存储2的8次方，256种状态，从00000000到11111111，换算为整数则是从0-255，也即一个字节可以表示256种字符

## ASCII

American Standard Code for Information Interchange，从缩写还原之后就可以顾名思义了，20世纪60年代计算机发明之初美国人制定的一套编码，包括了英文大小写字母，数字和一些符号共计128个字符

每个字符用一个字节存储，比如英文大写字母A，二进制存储编码是01000001，转为十进制的编码就是65，小写字母a，二进制存储编码01100001，十进制编码就是97

## 汉字编码

对于英语而言，ASCII码已经足够使用，但是世界上还有这么多语言，有很多超出ASCII码之外的字符，各个国家就制定了自己语言的编码，比如中国的GB2312编码

计算内存储汉字的编码又叫做汉字内码，使用两个字节来存储一个汉字，此外汉字的输入有专门的输入码（如拼音，五笔），输出显示也有对应的汉字字形码（汉字的显示是作为一个16X16的01点阵来表示，一个汉字的字形因此需要32个字节存储）

汉字由输入码输入，转为汉字内码存储，又转为字形码输出显示

## Unicode

由于每个国家采用编码的不同，不同编码保存的文件在打开之前则必须选择对应的编码方式，否则将显示乱码，但是与其寄希望于让打开文件的人能选择正确的编码，不如干脆让所有的文件都以统一的编码形式保存下来，这样不仅乱码的问题会大大减少，并且也简化了文件使用者的操作，同时文件使用者的机器上也不必装上所有的编码了

要实现这一点，那么就需要一套编码能够涵盖所有的语言符号，这个编码就是Unicode

Unicode是一套至今仍在不断发展的编码标准，目前已经有超过一百万个符号，每个符号都有对应的编码

Unicode中，英文和中文都采用两个字节进行表示，对于英文，只需要在ASCII码的基础上补八位0即可

## UTF-8

UTF-8是互联网广泛使用的一种编码方案，它其实是Unicode的一种实现和使用方式，Unicode只是定义了字符集，并不管如何编码到计算机上，如果计算机的存储完全按照Unicode编码来进行，那么就有一个显而易见的问题，比如一个纯英文的文件，用ASCII存储一个字母只需要一个字节，而Unicode存储，一个字母就需要两个字节，整个文件平白多出了一倍的空间，对于保存，读取和传输都十分不便，因而实际在使用时是以诸如UTF-8/UTF-16/UTF-32这些具体实现的编码方式来进行的

UTF-8是一种“可变长”的编码方案，它对Unicode进行了一定区间范围的划分，规定了每个范围内分别采用多少字节来进行存储

UTF-8向下兼容ASCII，英文在UTF-8中和ASCII完全一样，采用一个字节存储，而汉字在UTF-8中通常是3个字节存储的

但是UTF-8的缺点也在于此，由于一个字符可以是1-4个字节，内存在存储字节流的时候则必须遍历所有字节才能清楚知道哪个字符在哪个字节开始，这在算法上带来了时间上的开销，所以UTF-8主要用于存储和传输在于其空间优势（针对欧美英文而言，兼容ASCII的同时只需要一个字节存储），在计算机（操作系统）读取到内存的时候，又通常会转化成其他定长的编码方案，比如windows平台会转为UTF-16（大部分都采用定长的2字节存储），以达到降低运算时间的目的

不过UTF-8的出现比UTF-16晚，windows平台采用UTF-16也有其历史原因，而在JS和Python中，对字符串的处理是按UCS-2编码（这在曾经被称作Unicode编码，因为彼时Unicode还没有那么多字符，后来Unicode进行了扩充，于是出现了UTF-16，对于低位的两字节字符，UTF-16和UCS-2其实是一样的）进行的

UCS-2按一个字符两个字节存储，例如JS在处理的时候也会按照一个字符两个字节处理，遇到四个字节表示一个字符的，会当做两个双字节的字符，所以对这类字符进行字符编码操作会返回错误的结果，直到ES6扩充了对四个字节字符的支持

对于系统和语言，要让计算机采用什么样的编码方式处理并不是强制规定，有时间空间这些综合因素考量，也有兼容性方面的考虑，还有编码方案诞生时间早晚这样的历史因素，听说目前有的语言在内部处理字符串的标准实现也是按UTF-8来进行的，Linux和Mac似乎也是如此